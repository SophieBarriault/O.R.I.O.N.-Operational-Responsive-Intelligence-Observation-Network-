import speech_recognition as sr
import pyttsx3
import threading
import time
import tkinter as tk 
import openai 
import os 
from openai import OpenAI 
from huggingface_hub import InferenceClient

# Initialize client with your Hugging Face API token
hf_token = "insert_key_here"
client = InferenceClient(token=hf_token) 

# Initialize recognizer and TTS engine
recognizer = sr.Recognizer()
mic = sr.Microphone()
engine = pyttsx3.init()

# UI 
root = tk.Tk()
root.title("O.R.I.O.N. Debug Console")

text_display = tk.Text(root, height=20, width=80)
text_display.pack()


def update_ui(text):
    text_display.insert(tk.END, text + "\n")
    text_display.see(tk.END)


def speak(text):
    print(f"O.R.I.O.N.: {text}")
    update_ui(f"O.R.I.O.N.: {text}")
    engine.say(text)
    engine.runAndWait()

def get_hf_response(prompt):
    # Call the Gemma model for text generation
    response = client.text_generation(
        "google/gemma-2-2b-it",
        prompt,
        max_new_tokens=100,
        return_full_text=False,
        temperature=0.7
)


    # response is a list of dicts [{generated_text: "..."}]
    return response[0]['generated_text'] 
    #return f"(Mock reply to: {prompt})"


def listen_for_orion():
    with mic as source:
        recognizer.adjust_for_ambient_noise(source)

    while True:
        try:
            print("[Listening for wake word]")
            update_ui("[Listening for wake word...]")
            with mic as source:
                audio = recognizer.listen(source, timeout=8)
            wake_text = recognizer.recognize_google(audio)
            print(f"Heard: {wake_text}")
            update_ui(f"Heard: {wake_text}")

            if "orion" in wake_text.lower():
                print("Wake word detected!")
                update_ui("Wake word detected!")
                speak("Listening for your command now.")
                update_ui("O.R.I.O.N.: Listening...")
                listen_for_command()

        except sr.UnknownValueError:
            print("Could not understand audio.")
            update_ui("[Could not understand audio]")
        except sr.WaitTimeoutError:
            print("Listening timed out.")
            update_ui("[Listening timed out]")
        except Exception as e:
            print(f"Error: {e}")
            update_ui(f"[Error: {e}]")


def listen_for_command():
    try:
        with mic as source2:
            print("Listening for command...")
            update_ui("[Listening for command...]")
            audio2 = recognizer.listen(source2, timeout=8, phrase_time_limit=10)
            user_input = recognizer.recognize_google(audio2)

            print(f"User said: {user_input}")
            update_ui(f"You: {user_input}")

            reply = get_hf_response(user_input) 
            print(f"O.R.I.O.N.: {reply}")
            update_ui(f"O.R.I.O.N.: {reply}\n")
            speak(reply)

    except sr.UnknownValueError:
        update_ui("[Could not understand command]")
    except sr.RequestError as e:
        update_ui(f"[Speech API error: {e}]")
    except Exception as e:
        update_ui(f"[Unexpected error: {e}]")


# Run the assistant in a separate thread so UI stays responsive
threading.Thread(target=listen_for_orion, daemon=True).start()

root.mainloop() 
